<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>MIP specs on MIP specifications</title>
    <link>https://hbpmedical.github.io/specifications/</link>
    <description>Recent content in MIP specs on MIP specifications</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-uk</language>
    <copyright>Released under the MIT license</copyright>
    <lastBuildDate>Fri, 03 Feb 2017 16:30:51 +0200</lastBuildDate>
    
	<atom:link href="https://hbpmedical.github.io/specifications/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Flow in MIP Local</title>
      <link>https://hbpmedical.github.io/specifications/data-flow/mip-local/</link>
      <pubDate>Mon, 03 Jul 2017 11:44:00 +0200</pubDate>
      
      <guid>https://hbpmedical.github.io/specifications/data-flow/mip-local/</guid>
      <description>&lt;p&gt;MIP Local is installed in participating hospitals and used to collect clinical data
provided by the hospital. Only patients with consent are selected, and no data ever leaves
the hospital premises.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Flow in MIP Federation</title>
      <link>https://hbpmedical.github.io/specifications/data-flow/mip-federated/</link>
      <pubDate>Mon, 03 Jul 2017 11:44:00 +0200</pubDate>
      
      <guid>https://hbpmedical.github.io/specifications/data-flow/mip-federated/</guid>
      <description>&lt;p&gt;MIP Federated brings together several hospitals and clinical data centers to build a Federation.&lt;/p&gt;

&lt;p&gt;Data are collected at each hospital (clinical data) or clinical data centers (research data), then
a user of MIP can query and do machine learning or statistical analyses but with the strong imperative that
only data aggregates are exchanged between the hospital or data centers and the central node hosting the user-facing web site.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Data Capture input</title>
      <link>https://hbpmedical.github.io/specifications/data-capture/input/</link>
      <pubDate>Tue, 28 Feb 2017 20:08:35 +0100</pubDate>
      
      <guid>https://hbpmedical.github.io/specifications/data-capture/input/</guid>
      <description>Data Capture collects available data from hospital databases or research cohorts.
In addition, clinical data are de-personalised to protect patient privacy.
It should also track consent and trigger the appropriate mechanisms to remove data from the platform in case the patient has removed her consent.
Ideal forms of data repository for MIP The MIP has been designed to support a very wide range of methods to gather data, however some datasets are easier to include in the MIP if they meet some criteria.</description>
    </item>
    
    <item>
      <title>Anonymisation module</title>
      <link>https://hbpmedical.github.io/specifications/data-capture/anonymizer/</link>
      <pubDate>Tue, 28 Feb 2017 20:08:35 +0100</pubDate>
      
      <guid>https://hbpmedical.github.io/specifications/data-capture/anonymizer/</guid>
      <description>A module that performs anonymisation is provided by MIP when the hospital does not have the tools to perform the de-personalisation of all data.
The following is used only when the GNUBILA Pandora FedEHR anonymiser has been setup.
 Data folder organisation for the anonymisation processing The software GNUBILA Pandora FedEHR is used to perform the de-personalisation of all EHR and imaging data.
 /data ├── anonymiser -- This folder contains all the data being processed.</description>
    </item>
    
    <item>
      <title>Data Capture output</title>
      <link>https://hbpmedical.github.io/specifications/data-capture/output/</link>
      <pubDate>Fri, 03 Feb 2017 18:07:35 +0100</pubDate>
      
      <guid>https://hbpmedical.github.io/specifications/data-capture/output/</guid>
      <description>The Data Capture should export its data into a folder made available to the Data Factory
There are several options possible, to adapt to the local requirements:
Depersonalised DICOM + EHR data export  ├── DICOM │ └── 2016 -- yearly folder, date represents the date of export │ └── 20161029 -- daily folder, date represents the date of export │ └── scan_research_id -- see description below │ └── dicom_name_generated_01.dcm -- set of DICOM files │ └── dicom_name_generated_02.</description>
    </item>
    
    <item>
      <title>Data Factory input</title>
      <link>https://hbpmedical.github.io/specifications/data-factory/input/</link>
      <pubDate>Fri, 24 Feb 2017 16:15:35 +0100</pubDate>
      
      <guid>https://hbpmedical.github.io/specifications/data-factory/input/</guid>
      <description>The input of Data Factory is the output of Data Capture.
From Data Capture output specifications Depersonalised DICOM + EHR data export  ├── DICOM │ └── 2016 -- yearly folder, date represents the date of export │ └── 20161029 -- daily folder, date represents the date of export │ └── scan_research_id -- see description below │ └── dicom_name_generated_01.dcm -- set of DICOM files │ └── dicom_name_generated_02.dcm -- set of DICOM files │ └── dicom_name_generated_03.</description>
    </item>
    
    <item>
      <title>Requirements for imaging data</title>
      <link>https://hbpmedical.github.io/specifications/data-factory/images/</link>
      <pubDate>Tue, 11 Jul 2017 16:00:35 +0000</pubDate>
      
      <guid>https://hbpmedical.github.io/specifications/data-factory/images/</guid>
      <description>In order to be pre-processed by the Data Factory, the imaging data have to meet some requirements, both regarding the images format and the images meta-data.
Images format  The images must be full brain scans. The images must be provided either in DICOM or NIFTI format. The images must be high-resolution (max. 1.5 mm) T1-weighted sagittal images. If the dataset contains other types of images (that is not meeting the above description, e.</description>
    </item>
    
    <item>
      <title>Processing pipelines</title>
      <link>https://hbpmedical.github.io/specifications/data-factory/pipelines/</link>
      <pubDate>Tue, 04 Jul 2017 11:16:30 +0100</pubDate>
      
      <guid>https://hbpmedical.github.io/specifications/data-factory/pipelines/</guid>
      <description>The processing pipelines provided out-of-the-box by the Data Factory enable an automated processing of data made available to MIP Local or MIP Federated.
Overview of all pipelines graph LR data_in(Anonymised data from Data Capture or other sources) data_out(Research-grade data) reorg_pipeline Reorganisation pipeline] ehr_pipeline EHR curation pipeline] metadata_pipeline Metadata curation pipeline] preprocessing_pipeline MRI pre-processing and feature extraction pipeline] normalisation_pipeline Normalisation and data export pipeline] data_in -- reorg_pipeline reorg_pipeline -- ehr_pipeline reorg_pipeline -- metadata_pipeline reorg_pipeline -- preprocessing_pipeline ehr_pipeline -- normalisation_pipeline metadata_pipeline -- normalisation_pipeline preprocessing_pipeline -- normalisation_pipeline normalisation_pipeline -- data_out  Reorganisation pipeline This pipeline takes data organised on the disk in its original format and reorganise it into something that fits the layout expected by the following pipelines (EHR, pre-processing, metadata).</description>
    </item>
    
    <item>
      <title>Capture Database</title>
      <link>https://hbpmedical.github.io/specifications/data-factory/capture_i2b2/</link>
      <pubDate>Tue, 04 Jul 2017 11:16:30 +0100</pubDate>
      
      <guid>https://hbpmedical.github.io/specifications/data-factory/capture_i2b2/</guid>
      <description>Database with an I2B2 schema storing all information harvested onsite The Capture database enables the collection of lots of information coming from the hospital EHR data or from research cohort metadata in an unaltered way.
At this point, no attempt is made to select or transform the data to fit into the MIP Common Data Elements.
This database serves purely the data curation process: data elements are identified, described, collected and managed in a database.</description>
    </item>
    
    <item>
      <title>Common Data Elements</title>
      <link>https://hbpmedical.github.io/specifications/data-factory/cde/</link>
      <pubDate>Tue, 04 Jul 2017 11:16:30 +0100</pubDate>
      
      <guid>https://hbpmedical.github.io/specifications/data-factory/cde/</guid>
      <description></description>
    </item>
    
    <item>
      <title>CDE-normalised database</title>
      <link>https://hbpmedical.github.io/specifications/data-factory/cde_i2b2/</link>
      <pubDate>Tue, 04 Jul 2017 11:16:30 +0100</pubDate>
      
      <guid>https://hbpmedical.github.io/specifications/data-factory/cde_i2b2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Provenance</title>
      <link>https://hbpmedical.github.io/specifications/data-factory/provenance/</link>
      <pubDate>Tue, 04 Jul 2017 11:16:30 +0100</pubDate>
      
      <guid>https://hbpmedical.github.io/specifications/data-factory/provenance/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Data Factory output</title>
      <link>https://hbpmedical.github.io/specifications/data-factory/output/</link>
      <pubDate>Tue, 04 Jul 2017 11:16:30 +0100</pubDate>
      
      <guid>https://hbpmedical.github.io/specifications/data-factory/output/</guid>
      <description>The ouput of Data Factory is a set of research-grade data containing the biomarkers extracted from MRI scans and the variables extracted from the patient (or research subject) EHR records.
This information is sent to the Hospital Database and provided to the machine learning and statistical analysis algorithms of the Algorithm Factory as well as the distributed queries when the instance of MIP at a hospital is connected to the Federation.</description>
    </item>
    
    <item>
      <title>Distributed queries</title>
      <link>https://hbpmedical.github.io/specifications/hospital-database/distributed-queries/</link>
      <pubDate>Fri, 03 Feb 2017 17:18:42 +0100</pubDate>
      
      <guid>https://hbpmedical.github.io/specifications/hospital-database/distributed-queries/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Credits</title>
      <link>https://hbpmedical.github.io/specifications/credits/</link>
      <pubDate>Tue, 04 Jul 2017 00:30:51 +0200</pubDate>
      
      <guid>https://hbpmedical.github.io/specifications/credits/</guid>
      <description> Github contributors .ghContributors{ display:flex; flex-flow: wrap; align-content: flex-start } .ghContributors  div{ width: 50% ; display: inline-flex; margin-bottom: 5px; } .ghContributors  div label{ padding-left: 4px ; } .ghContributors  div span{ font-size: x-small; padding-left: 4px ; }   @ludovicc 39 commits   @sambuc 1 commits   @dianeperez 1 commits   Tooling  Netlify - Continuous deployment and hosting of this documentation Hugo   hugo-theme-docdock    </description>
    </item>
    
    <item>
      <title>header</title>
      <link>https://hbpmedical.github.io/specifications/_header/</link>
      <pubDate>Sat, 01 Jul 2017 18:36:24 +0200</pubDate>
      
      <guid>https://hbpmedical.github.io/specifications/_header/</guid>
      <description>Medical Informatics Platform</description>
    </item>
    
  </channel>
</rss>